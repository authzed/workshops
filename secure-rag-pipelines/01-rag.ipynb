{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d597dd80",
   "metadata": {},
   "source": [
    "# Fine Grained Authorization for Retrieval Augmented Generation (RAG)\n",
    "\n",
    "In the previous step we installed and launched an instance of SpiceDB. Now let's start building our RAG pipeline with fine grained authorization. \n",
    "\n",
    "\n",
    "This workshop simulates a simple usecase - We have user Tim that has access to two documents. We query a LLM for information from one of the documents. We then remove Tim's permissions to view one of the documents and make the same query. If all goes well, the information should not be available to him. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c372c",
   "metadata": {},
   "source": [
    "### Part 1: Add Secrets & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dda241c",
   "metadata": {},
   "source": [
    "Download the `requirements.txt` file from this directory and run the following command to install all dependencies for the workshop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c9205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9188659d",
   "metadata": {},
   "source": [
    "The consolidated list of imports are added at the start of the workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from authzed.api.v1 import (\n",
    "    Client,\n",
    "    WriteSchemaRequest,\n",
    "    WriteRelationshipsRequest,\n",
    "    RelationshipUpdate,\n",
    "    Relationship,\n",
    "    ObjectReference,\n",
    "    SubjectReference,\n",
    "    LookupResourcesRequest,\n",
    "    CheckPermissionRequest,\n",
    "    CheckPermissionResponse,\n",
    ")\n",
    "\n",
    "from grpcutil import insecure_bearer_token_credentials\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore, PineconeEmbeddings\n",
    "from langchain_core.runnables import (\n",
    "    RunnableParallel,\n",
    "    RunnableLambda,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from openai import AsyncOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f7666",
   "metadata": {},
   "source": [
    "This walkthrough requires the following environment variables. Create a file named `.env` in your working directory and add these variables:\n",
    "\n",
    "- ```OPENAI_API_KEY=<add OpenAI key>```\n",
    "- ```PINECONE_API_KEY=<add Pinecone key>```\n",
    "- ```SPICEDB_TOKEN=rag-rebac-walkthrough```\n",
    "- ```SPICEDB_ENDPOINT=localhost:50051```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c722945",
   "metadata": {},
   "source": [
    "Load the secrets into your app from the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8248a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "SPICEDB_ENDPOINT = os.getenv('SPICEDB_ENDPOINT')\n",
    "SPICEDB_TOKEN = os.getenv('SPICEDB_TOKEN')\n",
    "\n",
    "REQUIRED = {\n",
    "    'OPENAI_API_KEY': OPENAI_API_KEY,\n",
    "    'PINECONE_API_KEY': PINECONE_API_KEY,\n",
    "    'SPICEDB_ENDPOINT': SPICEDB_ENDPOINT,\n",
    "    'SPICEDB_TOKEN': SPICEDB_TOKEN,\n",
    "}\n",
    "missing = [k for k, v in REQUIRED.items() if not v]\n",
    "if missing:\n",
    "    raise RuntimeError(\n",
    "        'Missing env vars: ' + ', '.join(missing) +\n",
    "        '\\nSet them in your environment or a .env file in this directory.'\n",
    "    )\n",
    "\n",
    "# Make these available to downstream SDKs\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be225a51",
   "metadata": {},
   "source": [
    "### Part 2: Write a schema to SpiceDB\n",
    "\n",
    "In today's scenario, we will be authorizing fine-grain access to view blog articles.\n",
    "\n",
    "The source of truth for permissions in the RAG pipeline is SpiceDB. Create an instance of the SpiceDB client that we'll use for the workshop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdbe340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spicedb_client() -> Client:\n",
    "    # For TLS environments, replace with bearer_token_credentials(...).\n",
    "    return Client(\n",
    "        target=SPICEDB_ENDPOINT,\n",
    "        credentials=insecure_bearer_token_credentials(SPICEDB_TOKEN),\n",
    "    )\n",
    "\n",
    "_client = make_spicedb_client()\n",
    "print('SpiceDB client ready:', isinstance(_client, Client))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f356ea89",
   "metadata": {},
   "source": [
    "Let's begin by defining the authorization logic for our example. To do this, we write a [schema](https://authzed.com/docs/spicedb/concepts/schema) to SpiceDB. The schema below defines two object types, ```user``` and ```article```. Users can relate to a document as a ```viewer``` and any user who is related to a document as a ```viewer``` can ```view``` the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7092cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grpcutil import insecure_bearer_token_credentials\n",
    "\n",
    "SCHEMA = \"\"\"definition user {}\n",
    "\n",
    "definition article {\n",
    "    relation viewer: user\n",
    "\n",
    "    permission view = viewer\n",
    "}\"\"\"\n",
    "\n",
    "client = make_spicedb_client()\n",
    "\n",
    "try:\n",
    "    resp = await(client.WriteSchema(WriteSchemaRequest(schema=SCHEMA)))\n",
    "except Exception as e:\n",
    "    print(f\"Write schema error: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edaf49e",
   "metadata": {},
   "source": [
    "### Part 3: Write a Relationship to SpiceDB\n",
    "\n",
    "Now, we write relationships to SpiceDB that specify that Tim is a viewer of document 123 and 456.\n",
    "\n",
    "After these relationships are written, any permission checks to SpiceDB will reflect that Tim can view documents 123 and 456."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af300a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    resp = await (client.WriteRelationships(\n",
    "        WriteRelationshipsRequest(\n",
    "            updates=[\n",
    "                RelationshipUpdate(\n",
    "                    operation=RelationshipUpdate.Operation.OPERATION_TOUCH,\n",
    "                    relationship=Relationship(\n",
    "                        resource=ObjectReference(object_type=\"article\", object_id=\"123\"),\n",
    "                        relation=\"viewer\",\n",
    "                        subject=SubjectReference(\n",
    "                            object=ObjectReference(\n",
    "                                object_type=\"user\",\n",
    "                                object_id=\"tim\",\n",
    "                            )\n",
    "                        ),\n",
    "                    ),\n",
    "                ),\n",
    "                RelationshipUpdate(\n",
    "                    operation=RelationshipUpdate.Operation.OPERATION_TOUCH,\n",
    "                    relationship=Relationship(\n",
    "                        resource=ObjectReference(object_type=\"article\", object_id=\"456\"),\n",
    "                        relation=\"viewer\",\n",
    "                        subject=SubjectReference(\n",
    "                            object=ObjectReference(\n",
    "                                object_type=\"user\",\n",
    "                                object_id=\"tim\",\n",
    "                            )\n",
    "                        ),\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    ))\n",
    "except Exception as e:\n",
    "    print(f\"Write relationships error: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8922e2",
   "metadata": {},
   "source": [
    "### Part 4: Simulate a real-world RAG scenario\n",
    "\n",
    "We now define a Pinecone serverless index.\n",
    "\n",
    "Pinecone is a specialized database designed for handling vector-based data. Their serverless product makes it easy to get started with a vector DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3a8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"documents\"\n",
    "namespace_name = \"authzed\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=1024,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb61ba",
   "metadata": {},
   "source": [
    "We are simulating a real-world RAG (retrieval-augmented generation) scenario by embedding a completely fictional string: \"Bill Gates won the 2025 Oscar for best football movie.\". Since LLMs don't \"know\" this fact (as it's made up), we mimic a typical RAG case where private or unknown data augments prompts.\n",
    "\n",
    "In this example, we also specify metadata like article_id to track which article the string comes from. The article_id is important for linking embeddings to objects that users are authorized on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Document object that specifies our made up documents and specifies the document_id as metadata.\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Bill Gates won the 2025 Oscar for best football movie\",\n",
    "        metadata={\"article_id\": \"123\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"The revenue for Q4 2025 is one billion dollars!\",\n",
    "        metadata={\"article_id\": \"456\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "# Initialize LangChain embeddings\n",
    "embeddings = PineconeEmbeddings(\n",
    "    model=\"multilingual-e5-large\",\n",
    "    pinecone_api_key=PINECONE_API_KEY\n",
    ")\n",
    "\n",
    "# Create vector store and upsert both documents\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=documents,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings,\n",
    "    namespace=namespace_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b8508",
   "metadata": {},
   "source": [
    "### Part 5: Make a request when the user is authorized to view the necessary contextual data using the Pre-Filter Method\n",
    "\n",
    "Here is a high-level architecture diagram of the Pre-Filter method\n",
    "![pre-filter architecture diagram](/secure-rag-pipelines/images/secure-rag.png)\n",
    "\n",
    "We'll query SpiceDB for a list of documents that Tim is allowed to view using the [LookupResources API](https://buf.build/authzed/api/docs/main:authzed.api.v1#authzed.api.v1.LookupResourcesRequest). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891fca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = SubjectReference(\n",
    "    object=ObjectReference(\n",
    "        object_type=\"user\",\n",
    "        object_id=\"tim\",\n",
    "    )\n",
    ")\n",
    "\n",
    "def lookupArticles():\n",
    "    return client.LookupResources(\n",
    "        LookupResourcesRequest(\n",
    "            subject=subject,\n",
    "            permission=\"view\",\n",
    "            resource_object_type=\"article\",\n",
    "        )\n",
    "    )\n",
    "try:\n",
    "    resp = lookupArticles()\n",
    "\n",
    "    authorized_articles = []\n",
    "\n",
    "    async for response in resp:\n",
    "            authorized_articles.append(response.resource_object_id)\n",
    "except Exception as e:\n",
    "    print(f\"Lookup error: {type(e).__name__}: {e}\")\n",
    "\n",
    "print(\"Article IDs that Tim is authorized to view:\")\n",
    "print(authorized_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f1c9e4",
   "metadata": {},
   "source": [
    "We can now issue a prompt to GPT-5, enhanced with relevant data that the user is authorized to access. This ensures that the response is based on information the user is permitted to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ccfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ask function\n",
    "def ask():\n",
    "    # Initialize a LangChain object for an OpenAI chat model.\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key=OPENAI_API_KEY,\n",
    "        model=\"gpt-5-nano-2025-08-07\",\n",
    "        temperature=1\n",
    "    )\n",
    "\n",
    "    # Initialize a LangChain object for a Pinecone index with an OpenAI embeddings model.\n",
    "    knowledge = PineconeVectorStore.from_existing_index(\n",
    "        index_name=index_name,\n",
    "        namespace=namespace_name,\n",
    "        embedding=OpenAIEmbeddings(\n",
    "            openai_api_key=OPENAI_API_KEY,\n",
    "            dimensions=1024,\n",
    "            model=\"text-embedding-3-large\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Initialize a retriever with a filter that restricts the search to authorized documents.\n",
    "    retriever=knowledge.as_retriever(\n",
    "            search_kwargs={\n",
    "            \"filter\": {\n",
    "                \"article_id\":\n",
    "                    {\"$in\": authorized_articles},\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Initialize a string prompt template that let's us add context and a question.\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"Answer the question below using the context:\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Answer: \"\"\")\n",
    "\n",
    "    retrieval =  RunnableParallel(\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    )\n",
    "\n",
    "    chain = retrieval | prompt | llm | StrOutputParser()\n",
    "\n",
    "    question = \"\"\"Who won the Oscar for best football movie?\"\"\"\n",
    "\n",
    "    print(\"Prompt: \\n\")\n",
    "    print(question)\n",
    "    print(chain.invoke(question))\n",
    "\n",
    "#invoke the ask function\n",
    "ask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d92c14",
   "metadata": {},
   "source": [
    "You can also generate a summary of all the articles that Tim is authorized to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644fe273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize only articles that the user is authorized to view\n",
    "\n",
    "async def summarize_accessible_articles(user_id: str):\n",
    "\n",
    "    # 1️⃣ Lookup articles\n",
    "    subject = SubjectReference(\n",
    "        object=ObjectReference(object_type=\"user\", object_id=user_id)\n",
    "    )\n",
    "    response = client.LookupResources(\n",
    "        LookupResourcesRequest(\n",
    "            subject=subject,\n",
    "            permission=\"view\",\n",
    "            resource_object_type=\"article\",\n",
    "        )\n",
    "    )\n",
    "    authorized_articles = [res.resource_object_id async for res in response]\n",
    "    print(f\"🔍 {user_id} can view articles: {authorized_articles}\")\n",
    "\n",
    "    if not authorized_articles:\n",
    "        return \"❌ No accessible articles.\"\n",
    "\n",
    "    # 2️⃣ Setup LangChain retriever w/ filter\n",
    "    knowledge = PineconeVectorStore.from_existing_index(\n",
    "        index_name=index_name,\n",
    "        namespace=namespace_name,\n",
    "        embedding=OpenAIEmbeddings(\n",
    "            openai_api_key=OPENAI_API_KEY,\n",
    "            dimensions=1024,\n",
    "            model=\"text-embedding-3-large\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    retriever = knowledge.as_retriever(\n",
    "        search_kwargs={\n",
    "            \"filter\": {\"article_id\": {\"$in\": authorized_articles}},\n",
    "            \"k\": 100  # Ensure we get all matches\n",
    "        }\n",
    "    )\n",
    "\n",
    "    docs = await retriever.ainvoke(\"Give me all the contents to summarize\")\n",
    "\n",
    "    if not docs:\n",
    "        return \"❌ No content found.\"\n",
    "\n",
    "    combined_text = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "    # 3️⃣ Summarize using OpenAI\n",
    "    summary_prompt = (\n",
    "        \"You are an AI assistant. Based ONLY on the following articles, \"\n",
    "        \"generate a concise summary of their contents. Do not use any outside knowledge.\\n\\n\"\n",
    "        + combined_text\n",
    "        + \"\\n\\nSummary:\"\n",
    "    )\n",
    "\n",
    "    openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)\n",
    "    chat_response = await openai_client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n",
    "        model=\"gpt-5-nano-2025-08-07\",\n",
    "        temperature=1\n",
    "    )\n",
    "\n",
    "    return chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3783885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = await summarize_accessible_articles(\"tim\")\n",
    "print(\"📄 Summary of accessible articles:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4900c640",
   "metadata": {},
   "source": [
    "### Part 6: Make a request when the user is NOT authorized to view the necessary contextual data\n",
    "\n",
    "Now, let's see what happens when Tim is not authorized to view the document.\n",
    "\n",
    "First, we will delete the relationship that related Tim as a viewer to document 123."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde09648",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    resp = await client.WriteRelationships(\n",
    "        WriteRelationshipsRequest(\n",
    "            updates=[\n",
    "                RelationshipUpdate(\n",
    "                    operation=RelationshipUpdate.Operation.OPERATION_DELETE,\n",
    "                    relationship=Relationship(\n",
    "                        resource=ObjectReference(object_type=\"article\", object_id=\"123\"),\n",
    "                        relation=\"viewer\",\n",
    "                        subject=SubjectReference(\n",
    "                            object=ObjectReference(\n",
    "                                object_type=\"user\",\n",
    "                                object_id=\"tim\",\n",
    "                            )\n",
    "                        ),\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Write relationships error: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddaef6",
   "metadata": {},
   "source": [
    "Next, we will update the list of documents that Tim is authorized to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e744adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "        resp = lookupArticles()\n",
    "\n",
    "        authorized_articles = []\n",
    "\n",
    "        async for response in resp:\n",
    "                authorized_articles.append(response.resource_object_id)\n",
    "except Exception as e:\n",
    "    print(f\"Lookup error: {type(e).__name__}: {e}\")\n",
    "\n",
    "print(\"Documents that Tim can view:\")\n",
    "print(authorized_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea1c350",
   "metadata": {},
   "source": [
    "Now, we can run our query again. \n",
    "\n",
    "Note that we no longer recieve a completion that answers our question because Tim is no longer authorized to view the document that contains the context required to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function was defined above\n",
    "ask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45895a9",
   "metadata": {},
   "source": [
    "## Post-Filter Method\n",
    "\n",
    "We just completed the pre-filter method where we queried SpiceDB for all the documents that Tim was authorized to view. An alternate approach is to use the Post-Filter method where a [CheckPermissionRequest](https://buf.build/authzed/api/docs/main:authzed.api.v1#authzed.api.v1.CheckPermissionRequest) is performed on every document ID that the vector database returns. The list of authorized documents is then passed on to the LLM for a response to the query.\n",
    "\n",
    "Here is a high-level architecture diagram of the post-filter method\n",
    "![post-filter architecture diagram](/secure-rag-pipelines/images/post-filter.png)\n",
    "\n",
    "Choosing between the two depends on your usecase. Typically if you have a high positive hit-rate from your vector database, a post-filter approach works well. Conversely, if you have a large corpus of documents in your RAG pipeline and a low positive hit-rate, the pre-filter approach works better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f1c771",
   "metadata": {},
   "source": [
    "### Part 7: Restore Tim's permissions\n",
    "\n",
    "Let's restore Tim's permissions to view document `123`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4559a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    resp = await client.WriteRelationships(\n",
    "        WriteRelationshipsRequest(\n",
    "            updates=[\n",
    "                RelationshipUpdate(\n",
    "                    operation=RelationshipUpdate.Operation.OPERATION_TOUCH,\n",
    "                    relationship=Relationship(\n",
    "                        resource=ObjectReference(object_type=\"article\", object_id=\"123\"),\n",
    "                        relation=\"viewer\",\n",
    "                        subject=SubjectReference(\n",
    "                            object=ObjectReference(\n",
    "                                object_type=\"user\",\n",
    "                                object_id=\"tim\",\n",
    "                            )\n",
    "                        ),\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Write relationships error: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a61b2",
   "metadata": {},
   "source": [
    "### Part 8: Checking for Permissions\n",
    "\n",
    "Define the method that gets the `article_id` for all documents and checks whether the user has permissions for each article. Compare and contrast this with the Pre-Filter method where we performed a lookup to get a list of documents that the user had access to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2c3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def filter_docs_with_spicedb(docs: List):\n",
    "    filtered_docs = []\n",
    "    for doc in docs:\n",
    "        article_id = doc.metadata.get(\"article_id\")\n",
    "        resp = await client.CheckPermission(\n",
    "            CheckPermissionRequest(\n",
    "                subject=SubjectReference(\n",
    "                    object=ObjectReference(\n",
    "                        object_type=\"user\",\n",
    "                        object_id=\"tim\",\n",
    "                    ),\n",
    "                ),\n",
    "                resource=ObjectReference(\n",
    "                    object_type=\"article\",\n",
    "                    object_id=str(article_id),\n",
    "                ),\n",
    "                permission=\"view\",\n",
    "            )\n",
    "        )\n",
    "        if resp.permissionship == CheckPermissionResponse.PERMISSIONSHIP_HAS_PERMISSION:\n",
    "            filtered_docs.append(doc)\n",
    "        \n",
    "    return filtered_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e421e1",
   "metadata": {},
   "source": [
    "All that's left is to build a Langchain graph. This snippet sets up a retriever to fetch relevant documents, then applies a post-filter using SpiceDB to ensure only documents the user is authorized to view are included. \n",
    "\n",
    "`RunnableLambda` allows you to wrap a custom Python function (such as your authorization filter) so it can be used as a step in the LangChain pipeline. `RunnablePassthrough` simply passes its input through unchanged, making it useful for forwarding data (like the user's question) to the next step in the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e02bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LangChain graph\n",
    "retriever = docsearch.as_retriever(search_kwargs={\"k\": 4})\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, \n",
    "                 model=\"gpt-5-nano-2025-08-07\", \n",
    "                 temperature=1)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You answer strictly from the provided context. If insufficient, say so.\"),\n",
    "    (\"human\", \"Question: {question}\\n\\nContext:\\n{context}\")\n",
    "])\n",
    "\n",
    "# Combine: retrieve → post-filter → prompt → LLM\n",
    "graph = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": retriever | RunnableLambda(filter_docs_with_spicedb),\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"✅ Retrieval + chain wired up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c3724f",
   "metadata": {},
   "source": [
    "Run this code to ask the LLM about some data in document `123`. Since Tim does have permission to view this document, you should see the correct response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b806d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who won the 2025 Oscar for best football movie?\"\n",
    "result = await graph.ainvoke(question) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8612e495",
   "metadata": {},
   "source": [
    "Let's remove Tim's permission to view the document and then ask the same question again. Since Tim doesn't have permission to view this, document the LLM isn't able to provide an answer. We performed this step while testing the pre-filter method as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove Tim's permissions to view the contents of article \"123\"\n",
    "\n",
    "try: \n",
    "    resp = await client.WriteRelationships(\n",
    "        WriteRelationshipsRequest(\n",
    "            updates=[\n",
    "                RelationshipUpdate(\n",
    "                    operation=RelationshipUpdate.Operation.OPERATION_DELETE,\n",
    "                    relationship=Relationship(\n",
    "                        resource=ObjectReference(object_type=\"article\", object_id=\"123\"),\n",
    "                        relation=\"viewer\",\n",
    "                        subject=SubjectReference(\n",
    "                            object=ObjectReference(\n",
    "                                object_type=\"user\",\n",
    "                                object_id=\"tim\",\n",
    "                            )\n",
    "                        ),\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Write relationships error: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f34ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who won the 2025 Oscar for best football movie?\"\n",
    "result = await graph.ainvoke(question) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403efd05",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "You can now delete your Pinceone index if you'd like to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e514dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745dbc79",
   "metadata": {},
   "source": [
    "### Conclusion and Next Steps \n",
    "\n",
    "Congratulations! You learned how to secure your RAG pipelines with fine-grained authorization using SpiceDB. \n",
    "\n",
    "OpenAI uses SpiceDB and [AuthZed Dedicated](https://authzed.com/products/authzed-dedicated) to secure 37 Billion documents for 5 Million users who use ChatGPT Connectors. Read more about it here: https://authzed.com/customers/openai\n",
    "\n",
    "You can also use [AuthZed Cloud](https://authzed.com/products/authzed-cloud) for low-latency authorization at scale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

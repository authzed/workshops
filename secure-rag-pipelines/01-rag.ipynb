{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d597dd80",
   "metadata": {},
   "source": [
    "# Fine Grained Authorization for Retrieval Augmented Generation (RAG)\n",
    "\n",
    "In the previous step we installed and launched an instance of SpiceDB. Now let's start building our RAG pipeline with fine grained authorization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c372c",
   "metadata": {},
   "source": [
    "### Part 1: Add Secrets & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a963fa5c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `requirements.txt` file from this directory and run the following command to install all dependencies for the workshop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c9205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f7666",
   "metadata": {},
   "source": [
    "This walkthrough requires the following environment variables. Create a file named `.env` in your working directory and add these variables:\n",
    "\n",
    "- ```OPENAI_API_KEY=<add OpenAI key>```\n",
    "- ```PINECONE_API_KEY=<add Pinecone key>```\n",
    "- ```SPICEDB_API_KEY=rag-rebac-walkthrough```\n",
    "- ```SPICEDB_ADDR=localhost:50051```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c722945",
   "metadata": {},
   "source": [
    "Load the secrets into your app from the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8248a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "#load secrets from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be225a51",
   "metadata": {},
   "source": [
    "### Part 2: Write a schema to SpiceDB\n",
    "\n",
    "In today's scenario, we will be authorizing access to view blog articles.\n",
    "\n",
    "We will begin by defining the authorization logic for our example. To do this, we write a [schema](https://authzed.com/docs/spicedb/concepts/schema) to SpiceDB. The schema below defines two object types, ```user``` and ```article```. Users can relate to a document as a ```viewer``` and any user who is related to a document as a ```viewer``` can ```view``` the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7092cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from authzed.api.v1 import (\n",
    "    Client,\n",
    "    WriteSchemaRequest,\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "#change to bearer_token_credentials if you are using tls\n",
    "from grpcutil import insecure_bearer_token_credentials\n",
    "\n",
    "SCHEMA = \"\"\"definition user {}\n",
    "\n",
    "definition article {\n",
    "    relation viewer: user\n",
    "\n",
    "    permission view = viewer\n",
    "}\"\"\"\n",
    "\n",
    "client = Client(os.getenv('SPICEDB_ADDR'), insecure_bearer_token_credentials(os.getenv('SPICEDB_API_KEY')))\n",
    "\n",
    "try:\n",
    "    resp = await(client.WriteSchema(WriteSchemaRequest(schema=SCHEMA)))\n",
    "except Exception as e:\n",
    "    print(f\"Write schema error: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edaf49e",
   "metadata": {},
   "source": [
    "### Part 3: Write a Relationship to SpiceDB\n",
    "\n",
    "Now, we write relationships to SpiceDB that specify that Tim is a viewer of document 123 and 456.\n",
    "\n",
    "After these relationships are written, any permission checks to SpiceDB will reflect that Tim can view documents 123 and 456."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af300a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from authzed.api.v1 import (\n",
    "    ObjectReference,\n",
    "    Relationship,\n",
    "    RelationshipUpdate,\n",
    "    SubjectReference,\n",
    "    WriteRelationshipsRequest,\n",
    ")\n",
    "\n",
    "try:\n",
    "    resp = await (client.WriteRelationships(\n",
    "        WriteRelationshipsRequest(\n",
    "            updates=[\n",
    "                RelationshipUpdate(\n",
    "                    operation=RelationshipUpdate.Operation.OPERATION_TOUCH,\n",
    "                    relationship=Relationship(\n",
    "                        resource=ObjectReference(object_type=\"article\", object_id=\"123\"),\n",
    "                        relation=\"viewer\",\n",
    "                        subject=SubjectReference(\n",
    "                            object=ObjectReference(\n",
    "                                object_type=\"user\",\n",
    "                                object_id=\"tim\",\n",
    "                            )\n",
    "                        ),\n",
    "                    ),\n",
    "                ),\n",
    "                RelationshipUpdate(\n",
    "                    operation=RelationshipUpdate.Operation.OPERATION_TOUCH,\n",
    "                    relationship=Relationship(\n",
    "                        resource=ObjectReference(object_type=\"article\", object_id=\"456\"),\n",
    "                        relation=\"viewer\",\n",
    "                        subject=SubjectReference(\n",
    "                            object=ObjectReference(\n",
    "                                object_type=\"user\",\n",
    "                                object_id=\"tim\",\n",
    "                            )\n",
    "                        ),\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    ))\n",
    "except Exception as e:\n",
    "    print(f\"Write relationships error: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8922e2",
   "metadata": {},
   "source": [
    "### Part 4: Simulate a real-world RAG scenario\n",
    "\n",
    "We now define a Pinecone serverless index.\n",
    "\n",
    "Pinecone is a specialized database designed for handling vector-based data. Their serverless product makes it easy to get started with a vector DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3a8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "index_name = \"oscars\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=1024,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb61ba",
   "metadata": {},
   "source": [
    "We are simulating a real-world RAG (retrieval-augmented generation) scenario by embedding a completely fictional string: \"Bill Gates won the 2025 Oscar for best football movie.\". Since LLMs don't \"know\" this fact (as it's made up), we mimic a typical RAG case where private or unknown data augments prompts.\n",
    "\n",
    "In this example, we also specify metadata like article_id to track which article the string comes from. The article_id is important for linking embeddings to objects that users are authorized on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "from langchain.schema import Document\n",
    "import os\n",
    "\n",
    "# Create an object that has the contents of the articles and specifies the document_id as metadata.\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Bill Gates won the 2025 Oscar for best football movie\",\n",
    "        metadata={\"article_id\": \"123\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"The revenue for Q4 2025 is one billion dollars!\",\n",
    "        metadata={\"article_id\": \"456\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "# Initialize LangChain embeddings\n",
    "embeddings = PineconeEmbeddings(\n",
    "    model=\"multilingual-e5-large\",\n",
    "    pinecone_api_key=os.environ.get(\"PINECONE_API_KEY\")\n",
    ")\n",
    "\n",
    "# Create vector store and upsert both documents\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=documents,\n",
    "    index_name=\"oscars\",\n",
    "    embedding=embeddings,\n",
    "    namespace=\"oscar\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b8508",
   "metadata": {},
   "source": [
    "### Part 5: Make a request when the user is authorized to view the necessary contextual data\n",
    "\n",
    "Next, we will query SpiceDB for a list of documents that Tim is allowed to view. Here, we use the [LookupResources API](https://buf.build/authzed/api/docs/main:authzed.api.v1#authzed.api.v1.LookupResourcesRequest) to obtain a list of articles that ```tim``` has ```view``` permission on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891fca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from authzed.api.v1 import (\n",
    "    LookupResourcesRequest,\n",
    "    ObjectReference,\n",
    "    SubjectReference,\n",
    ")\n",
    "\n",
    "subject = SubjectReference(\n",
    "    object=ObjectReference(\n",
    "        object_type=\"user\",\n",
    "        object_id=\"tim\",\n",
    "    )\n",
    ")\n",
    "\n",
    "def lookupArticles():\n",
    "    return client.LookupResources(\n",
    "        LookupResourcesRequest(\n",
    "            subject=subject,\n",
    "            permission=\"view\",\n",
    "            resource_object_type=\"article\",\n",
    "        )\n",
    "    )\n",
    "try:\n",
    "    resp = lookupArticles()\n",
    "\n",
    "    authorized_articles = []\n",
    "\n",
    "    async for response in resp:\n",
    "            authorized_articles.append(response.resource_object_id)\n",
    "except Exception as e:\n",
    "    print(f\"Lookup error: {type(e).__name__}: {e}\")\n",
    "\n",
    "print(\"Article IDs that Tim is authorized to view:\")\n",
    "print(authorized_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f1c9e4",
   "metadata": {},
   "source": [
    "We can now issue a prompt to GPT-3.5, enhanced with relevant data that the user is authorized to access. This ensures that the response is based on information the user is permitted to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ccfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.runnables import (\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough\n",
    ")\n",
    "\n",
    "# Define the ask function\n",
    "def ask():\n",
    "    # Initialize a LangChain object for an OpenAI chat model.\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "    # Initialize a LangChain object for a Pinecone index with an OpenAI embeddings model.\n",
    "    knowledge = PineconeVectorStore.from_existing_index(\n",
    "        index_name=index_name,\n",
    "        namespace=namespace_name,\n",
    "        embedding=OpenAIEmbeddings(\n",
    "            openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "            dimensions=1024,\n",
    "            model=\"text-embedding-3-large\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Initialize a retriever with a filter that restricts the search to authorized documents.\n",
    "    retriever=knowledge.as_retriever(\n",
    "            search_kwargs={\n",
    "            \"filter\": {\n",
    "                \"article_id\":\n",
    "                    {\"$in\": authorized_articles},\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Initialize a string prompt template that let's us add context and a question.\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"Answer the question below using the context:\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Answer: \"\"\")\n",
    "\n",
    "    retrieval =  RunnableParallel(\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    )\n",
    "\n",
    "    chain = retrieval | prompt | llm | StrOutputParser()\n",
    "\n",
    "    question = \"\"\"Who won the 2025 Oscar for best football movie?\"\"\"\n",
    "\n",
    "    print(\"Prompt: \\n\")\n",
    "    print(question)\n",
    "    print(chain.invoke(question))\n",
    "\n",
    "#invoke the ask function\n",
    "ask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d92c14",
   "metadata": {},
   "source": [
    "You can also generate a summary of all the articles that Tim is authorized to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644fe273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize only articles that the user is authorized to view\n",
    "\n",
    "async def summarize_accessible_articles(user_id: str):\n",
    "    from authzed.api.v1 import LookupResourcesRequest, ObjectReference, SubjectReference\n",
    "    from langchain_pinecone import PineconeVectorStore\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    from openai import AsyncOpenAI\n",
    "    import os\n",
    "\n",
    "    # Lookup articles\n",
    "    subject = SubjectReference(\n",
    "        object=ObjectReference(object_type=\"user\", object_id=user_id)\n",
    "    )\n",
    "    response = client.LookupResources(\n",
    "        LookupResourcesRequest(\n",
    "            subject=subject,\n",
    "            permission=\"view\",\n",
    "            resource_object_type=\"article\",\n",
    "        )\n",
    "    )\n",
    "    authorized_articles = [res.resource_object_id async for res in response]\n",
    "    print(f\"🔍 {user_id} can view articles: {authorized_articles}\")\n",
    "\n",
    "    if not authorized_articles:\n",
    "        return \"❌ No accessible articles.\"\n",
    "\n",
    "    # Setup LangChain retriever w/ filter\n",
    "    knowledge = PineconeVectorStore.from_existing_index(\n",
    "        index_name=index_name,\n",
    "        namespace=namespace_name,\n",
    "        embedding=OpenAIEmbeddings(\n",
    "            openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "            dimensions=1024,\n",
    "            model=\"text-embedding-3-large\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    retriever = knowledge.as_retriever(\n",
    "        search_kwargs={\n",
    "            \"filter\": {\"article_id\": {\"$in\": authorized_articles}},\n",
    "            \"k\": 100  # Ensure we get all matches\n",
    "        }\n",
    "    )\n",
    "\n",
    "    docs = await retriever.ainvoke(\"Give me all the contents to summarize\")\n",
    "\n",
    "    if not docs:\n",
    "        return \"❌ No content found.\"\n",
    "\n",
    "    combined_text = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "    # 3️⃣ Summarize using OpenAI\n",
    "    summary_prompt = (\n",
    "        \"You are an AI assistant. Based ONLY on the following articles, \"\n",
    "        \"generate a concise summary of their contents. Do not use any outside knowledge.\\n\\n\"\n",
    "        + combined_text\n",
    "        + \"\\n\\nSummary:\"\n",
    "    )\n",
    "\n",
    "    openai_client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    chat_response = await openai_client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n",
    "        model=\"gpt-4\",\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3783885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = await summarize_accessible_articles(\"tim\")\n",
    "print(\"📄 Summary of accessible articles:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4900c640",
   "metadata": {},
   "source": [
    "### Part 6: Make a request when the user is NOT authorized to view the necessary contextual data\n",
    "\n",
    "Now, let's see what happens when Tim is not authorized to view the document.\n",
    "\n",
    "First, we will delete the relationship that related Tim as a viewer to document 123."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde09648",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    resp = await client.WriteRelationships(\n",
    "        WriteRelationshipsRequest(\n",
    "            updates=[\n",
    "                RelationshipUpdate(\n",
    "                    operation=RelationshipUpdate.Operation.OPERATION_DELETE,\n",
    "                    relationship=Relationship(\n",
    "                        resource=ObjectReference(object_type=\"article\", object_id=\"123\"),\n",
    "                        relation=\"viewer\",\n",
    "                        subject=SubjectReference(\n",
    "                            object=ObjectReference(\n",
    "                                object_type=\"user\",\n",
    "                                object_id=\"tim\",\n",
    "                            )\n",
    "                        ),\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Write relationships error: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddaef6",
   "metadata": {},
   "source": [
    "Next, we will update the list of documents that Tim is authorized to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e744adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function was defined above\n",
    "try:\n",
    "        resp = lookupArticles()\n",
    "\n",
    "        authorized_articles = []\n",
    "\n",
    "        async for response in resp:\n",
    "                authorized_articles.append(response.resource_object_id)\n",
    "except Exception as e:\n",
    "    print(f\"Lookup error: {type(e).__name__}: {e}\")\n",
    "\n",
    "print(\"Documents that Tim can view:\")\n",
    "print(authorized_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea1c350",
   "metadata": {},
   "source": [
    "Now, we can run our query again. \n",
    "\n",
    "Note that we no longer recieve a completion that answers our question because Tim is no longer authorized to view the document that contains the context required to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function was defined above\n",
    "ask()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403efd05",
   "metadata": {},
   "source": [
    "### Part 7: Conclusion and Next Steps \n",
    "\n",
    "You can now delete your Pinceone index if you'd like to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e514dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.delete_index(index_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
